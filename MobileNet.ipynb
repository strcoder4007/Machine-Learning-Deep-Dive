{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Transfer Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow.keras.layers as tfl\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (160, 160)\n",
    "train_directory = '../datasets/tiny-imagenet-200/train'\n",
    "validation_directory = '../datasets/tiny-imagenet-200/val'\n",
    "train_dataset = image_dataset_from_directory(train_directory, \n",
    "                                            shuffle=True, \n",
    "                                            batch_size=BATCH_SIZE, \n",
    "                                            image_size=IMG_SIZE, \n",
    "                                            validation_split=0.2,\n",
    "                                            subset='training',\n",
    "                                            seed=42)\n",
    "validation_dataset = image_dataset_from_directory(validation_directory,\n",
    "                                            shuffle=True,\n",
    "                                            image_size=IMG_SIZE, \n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            validation_split=0.2,\n",
    "                                            subset='validation',\n",
    "                                            seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i+1)\n",
    "        plt.imshow(images[i].numpy().astype('uint8'))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Prefetch</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Augment Data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmenter():\n",
    "    data_augmentation = tf.keras.Sequential()\n",
    "    data_augmentation.add(RandomFlip('horizontal'))\n",
    "    data_augmentation.add(RandomRotation(0.2))\n",
    "    return data_augmentation\n",
    "\n",
    "augmenter = data_augmenter()\n",
    "\n",
    "for image, _ in train_dataset.take(1):\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    first_image = image[0]\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i+1)\n",
    "        augmented_image = augmenter(tf.expand_dims(first_image, 0))\n",
    "        plt.imshow(augmented_image[0]/255)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "IMG_SHAPE = IMG_SIZE + (3, )\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=True, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_dataset))\n",
    "base_model.trainable = False\n",
    "image_var = tf.Variable(image_batch)\n",
    "pred = base_model(image_var)\n",
    "\n",
    "tf.keras.applications.mobilenet_v2.decode_predictions(pred.numpy(), top=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Freeze all layers of MobileNetV2 except the Top layer (FC Dense layer) and train it</h3>\n",
    "<p>First we build the model, define the shapes of the input data and layers<br>\n",
    "Then we compile the model, define the hyperparameters such as learning rate, type of loss, metrics etc.<br>\n",
    "Then we <code>.fit</code> (train) the model, data is fed in the model in this stage and epochs is defined</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpaca_model(image_shape=IMG_SIZE, data_augmentation=data_augmenter()):\n",
    "    # Make space for 3 color channels i.e RGB therefore adding another dimension of value 3\n",
    "    input_shape = image_shape + (3,)\n",
    "    # Define the model, make sure to exclude the top most layer so we can add our own layer and train that particular layer\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "    # Freeze the whole model\n",
    "    base_model.trainable = False\n",
    "    # I guess this is where we inject the input data, injection point is tf.keras.Input as far as I understand\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    # augment the input data to make it 9 times\n",
    "    x = data_augmentation(inputs)\n",
    "    # Don't know what this does\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    # This training parameter is for batch norm layer, I dont understand how \n",
    "    # This is functional api so we can pass parameters like this \n",
    "    x = base_model(x, training=False)\n",
    "    # From here on out we are adding our own layers\n",
    "    x = tfl.GlobalAveragePooling2D()(x)\n",
    "    # Dropout to reduce overfitting\n",
    "    x = tfl.Dropout(0.2)(x)\n",
    "\n",
    "    # This would be the last layer, also this is the layer which we will train\n",
    "    prediction_layer = tfl.Dense(1)\n",
    "    outputs = prediction_layer(x)\n",
    "    \n",
    "    # As far as I understand, keras.Model take all the layers between inputs and outputs (both inclusive) \n",
    "    # and makes a model out of it\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = alpaca_model(IMG_SIZE, data_augmentation=data_augmenter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Compile the model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.01\n",
    "model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate), \n",
    "               loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Train the model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2500/2500 [==============================] - 60s 24ms/step - loss: -1117308.8750 - accuracy: 0.0049 - val_loss: 17837.3281 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2500/2500 [==============================] - 60s 24ms/step - loss: -2599142.2500 - accuracy: 0.0049 - val_loss: 32056.1855 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2500/2500 [==============================] - 59s 23ms/step - loss: -4082341.0000 - accuracy: 0.0049 - val_loss: 46275.6641 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2500/2500 [==============================] - 59s 24ms/step - loss: -5564080.5000 - accuracy: 0.0049 - val_loss: 60496.6523 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2500/2500 [==============================] - 60s 24ms/step - loss: -7042822.0000 - accuracy: 0.0049 - val_loss: 74702.1094 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "initial_epochs = 5\n",
    "history = model2.fit(train_dataset, validation_data=validation_dataset, epochs=initial_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
